{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.special import logsumexp\n",
    "from shapely.geometry import shape\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "np.random.seed(888)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current working directory\n",
    "cwd = os.getcwd()\n",
    "# Remove all children directories\n",
    "rd = os.path.join(cwd.split('stochastic-travel-demand-modelling/', 1)[0])\n",
    "# Make sure directory ends with project's name\n",
    "if not rd.endswith('stochastic-travel-demand-modelling'):\n",
    "    rd = os.path.join(rd,'stochastic-travel-demand-modelling/')\n",
    "    \n",
    "sys.path.append('..')\n",
    "\n",
    "from models.doubly_constrained.spatial_interaction_model import SpatialInteraction as DSIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data\n",
    "\n",
    "## Origin and destination locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set artificial info for destination sizes\n",
    "dataset = 'synthetic'\n",
    "var = 'dummy'\n",
    "filepath = '../data/input/synthetic'\n",
    "init_year = 0\n",
    "final_year = 5\n",
    "cambridge_data = True # False would generate Ward locations and randomly populate cost and flow matrix\n",
    "\n",
    "# Take subset of origins and destinations \n",
    "N = 2\n",
    "M = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cambridge_data:\n",
    "    # Import processed ward coordinates\n",
    "    ward_coordinates = gpd.read_file(\"../data/input/misc/ward_coordinates.json\")\n",
    "    n_locs = ward_coordinates.shape[0]\n",
    "    \n",
    "    if N == 1:\n",
    "        origins = [ward_coordinates[['ward_new','geometry']][0].values]\n",
    "    else:\n",
    "        origins = ward_coordinates[['ward_new','geometry']][0:N].values\n",
    "    if M == 1: \n",
    "        destinations = [ward_coordinates[['ward_new','geometry']][0].values]\n",
    "    else:\n",
    "        destinations = ward_coordinates[['ward_new','geometry']][0:M].values\n",
    "\n",
    "\n",
    "    # Get origin and destination locations\n",
    "    origin_locs = [[x[1].centroid.x,x[1].centroid.y] for x in origins]\n",
    "    destination_locs = [[x[1].centroid.x,x[1].centroid.y] for x in destinations]\n",
    "\n",
    "    # # Get origin and destination names\n",
    "    origin_names = [x[0] for x in origins]\n",
    "    destination_names = [x[0] for x in destinations]\n",
    "    \n",
    "else:\n",
    "    # Manually create coordinates\n",
    "    origins = [\n",
    "        {\n",
    "          \"type\": \"Feature\",\n",
    "          \"properties\": {\"name\":\"homerton\"},\n",
    "          \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [\n",
    "              0.15106201171874997,\n",
    "              52.175510777101074\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"Feature\",\n",
    "          \"properties\": {\"name\":\"hughes_hall\"},\n",
    "          \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [\n",
    "              0.13355255126953125,\n",
    "              52.19950596108069\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"Feature\",\n",
    "          \"properties\": {\"name\":\"newnham\"},\n",
    "          \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [\n",
    "              0.10282516479492186,\n",
    "              52.196138997125985\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "\n",
    "    destinations = [\n",
    "        {\n",
    "          \"type\": \"Feature\",\n",
    "          \"properties\": {\"name\":\"west_cam\"},\n",
    "          \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [\n",
    "              0.08050918579101562,\n",
    "              52.212760902425885\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"Feature\",\n",
    "          \"properties\": {\"name\":\"central_cam\"},\n",
    "          \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [\n",
    "              0.12205123901367186,\n",
    "              52.20424032262008\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Get origin and destination locations\n",
    "    origin_locs = [[shape(x['geometry']).x,shape(x['geometry']).y] for x in origins]\n",
    "    destination_locs = [[shape(x['geometry']).x,shape(x['geometry']).y] for x in destinations]\n",
    "\n",
    "    # Get origin and destination names\n",
    "    origin_names = [x['properties']['name'] for x in origins]\n",
    "    destination_names = [x['properties']['name'] for x in destinations]\n",
    "    \n",
    "    \n",
    "    if N == 1:\n",
    "        origins = [origins[0]]\n",
    "    else:\n",
    "        origins = origins[0:(N+1)]\n",
    "    if M == 1: \n",
    "        destinations = [destinations[0]]\n",
    "    else:\n",
    "        destinations = destinations[0:(M+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set true parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set true alpha and beta\n",
    "true_alpha = 1.5#1.1\n",
    "true_beta = 4\n",
    "true_delta = 0\n",
    "true_kappa = 1\n",
    "true_gamma = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create origin-destination data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set cost matrix\n",
    "cost_matrix = np.ones((N,M))\n",
    "if N != 2 and M != 2:\n",
    "    cost_matrix = np.random.randint(1,(N+1)*(M+1), size=(N,M))\n",
    "    #     for j in range(M):\n",
    "#         cost_matrix[:,j] = np.ones(N)*np.random.randint(1,M+1, size=1)\n",
    "else:\n",
    "    cost_matrix[0,1] = 2\n",
    "    cost_matrix[1,0] = 2\n",
    "\n",
    "# Normalise cost matrix\n",
    "c = cost_matrix/np.sum(cost_matrix)\n",
    "\n",
    "# Set origin supply\n",
    "origin_supply = np.random.randint(1,(N+1)*(M+1), size=(N)) #np.ones(N)\n",
    "o = origin_supply/np.sum(origin_supply)\n",
    "\n",
    "# Set destination demand\n",
    "destination_demand = np.random.randint(1,(N+1)*(M+1), size=(M))\n",
    "d = destination_demand/np.sum(destination_demand)\n",
    "\n",
    "# Set destination sizes\n",
    "initial_destination_sizes = (true_kappa + true_delta * M) * destination_demand\n",
    "xd = np.log(initial_destination_sizes/np.sum(initial_destination_sizes))\n",
    "\n",
    "# # Construct flow matrix\n",
    "T = np.zeros((N,M))\n",
    "\n",
    "# Define parameters\n",
    "theta = np.array([true_alpha, true_beta, true_delta, true_gamma, true_kappa, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "# Construct flow matrix\n",
    "si = DSIM(dataset)\n",
    "\n",
    "value = si.infer_flows_ipf_procedure(T,\n",
    "                                o,\n",
    "                                d,\n",
    "                                c,\n",
    "                                np.exp(xd),\n",
    "                                np.ones(N),\n",
    "                                np.ones(M),\n",
    "                                N,\n",
    "                                M,\n",
    "                                theta,\n",
    "                                10000,\n",
    "                                0.000000001,\n",
    "                                False)\n",
    "\n",
    "# for i in range(N):\n",
    "#     for j in range(M):\n",
    "#         _sum = 0\n",
    "#         # Compute denominator\n",
    "#         for jj in range(M):\n",
    "#             _sum += np.exp(true_alpha*xd[j]-true_beta*c[i,jj])\n",
    "#         # Compute estimated flow\n",
    "#         T[i,j] = o[i]*np.exp(true_alpha*xd[j]-true_beta*c[i,j]) / _sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost matrix\n",
      "       0      1      2\n",
      "0  0.125  0.250  0.125\n",
      "1  0.250  0.125  0.125\n",
      "Flow matrix\n",
      "          0         1         2\n",
      "0  0.069531  0.010380  0.045089\n",
      "1  0.353545  0.143466  0.377988\n"
     ]
    }
   ],
   "source": [
    "print('Cost matrix')\n",
    "print(pd.DataFrame(c))\n",
    "\n",
    "print('Flow matrix')\n",
    "print(pd.DataFrame(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated destination demand\n",
      "[0.06666667 0.66666667 0.26666667]\n",
      "actual destination demand\n",
      "[0.06666667 0.66666667 0.26666667]\n",
      "actual destination sizes\n",
      "[0.06666667 0.66666667 0.26666667]\n"
     ]
    }
   ],
   "source": [
    "print('estimated destination demand')\n",
    "print(np.sum(T,axis=0))\n",
    "print('actual destination demand')\n",
    "print(d)\n",
    "print('actual destination sizes')\n",
    "print(np.exp(xd)/true_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated origin supply\n",
      "[0.66666667 0.33333333]\n",
      "actual origin supply\n",
      "[0.66666667 0.33333333]\n"
     ]
    }
   ],
   "source": [
    "print('estimated origin supply')\n",
    "print(np.sum(T,axis=1))\n",
    "print('actual origin supply')\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify equilibria number and stability\n",
    "\n",
    "This is based on \n",
    "- [1]: page 478 of Rijk, F. J. A., & Vorst, A. C. F. (1983). On the Uniqueness and Existence of Equilibrium Points in an Urban Retail Model. Environment and Planning A: Economy and Space, 15(4), 475–482. https://doi.org/10.1068/a150475\n",
    "- [2]: page 391 of Rijk, F. J. A., & Vorst, A. C. F. (1983). Equilibrium points in an urban retail model and their connection with dynamical systems. Regional Science and Urban Economics, 13(3), 383–399. https://doi.org/10.1016/0166-0462(83)90024-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "if M == 2 and N == 2:\n",
    "    cost = true_kappa*(c[0,0]**2 + c[0,1]**2)\n",
    "    a = true_kappa*(c[0,0]*c[0,1])\n",
    "    p = cost/(2*a)\n",
    "    p0 = np.ones((M)) * N/(2*true_kappa)\n",
    "    \n",
    "    if c[0,1] != c[1,0]:\n",
    "        raise ValueError(f\"This is not a symmetric cost matrix {c}\")\n",
    "    \n",
    "    if 0 < true_alpha and true_alpha <= 0.5:\n",
    "        # Obtained from [1]\n",
    "        print('There is exactly 1 unique possible solution to this dynamical system.')\n",
    "    elif true_alpha < 1 or true_alpha >= (0.5*(1+p)):\n",
    "        # Obtained from [1,2]\n",
    "        print('There is exactly 1 possible solution to this dynamical system.')\n",
    "    elif true_alpha > 1 and true_alpha < (0.5*(1+p)): \n",
    "        # Obtained from [2]\n",
    "        print('There is exactly 3 possible solutions to this dynamical system.')\n",
    "    else:\n",
    "        print('This is an unknown case.')\n",
    "        \n",
    "    if true_alpha > (0.5*(1+p)):\n",
    "        print(f'P0 {p0} is unstable.')\n",
    "    elif true_alpha < (0.5*(1+p)): \n",
    "        print(f'P0 {p0} is stable.')\n",
    "    else:\n",
    "        print('This is an unknown case.')\n",
    "        \n",
    "    print(true_alpha,0.5*(1+p),p)\n",
    "    \n",
    "    print(np.min(np.exp(xd)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cost matrix\n",
    "np.savetxt(f'../data/input/{dataset}/cost_matrix.txt',cost_matrix)\n",
    "\n",
    "# Export flow matrix\n",
    "np.savetxt(f'../data/input/{dataset}/od_matrix.txt',T)\n",
    "\n",
    "# Export origin-related data to txt\n",
    "np.savetxt(f'../data/input/{dataset}/origin_supply.txt',origin_supply)\n",
    "np.savetxt(f'../data/input/{dataset}/origin_locations.txt',origin_locs)\n",
    "np.savetxt(f'../data/input/{dataset}/origins.txt',origin_names,fmt=\"%s\")\n",
    "\n",
    "# Export destination-related data to txt\n",
    "np.savetxt(f'../data/input/{dataset}/destination_demand.txt',destination_demand)\n",
    "np.savetxt(f'../data/input/{dataset}/destination_locations.txt',destination_locs)\n",
    "np.savetxt(f'../data/input/{dataset}/destinations.txt',destination_names,fmt=\"%s\")\n",
    "\n",
    "# Export destination sizes to txt\n",
    "np.savetxt(f'../data/input/{dataset}/initial_destination_sizes.txt',initial_destination_sizes)\n",
    "# np.savetxt(f'../data/input/{dataset}/final_destination_sizes.txt',final_destination_sizes)\n",
    "\n",
    "# Export semantic meaning of destination sizes\n",
    "with open(f\"../data/input/{dataset}/destination_sizes_info.txt\", \"w\") as text_file:\n",
    "    print(f\"destination_sizes_data_filepath,{filepath}\", file=text_file)\n",
    "    print(f\"destination_sizes_variable,{var}\", file=text_file)\n",
    "    print(f\"initial_destination_sizes_year,{str(init_year)}\", file=text_file)\n",
    "#     print(f\"final_destination_sizes_year,{str(final_year)}\", file=text_file)\n",
    "    print(f\"true_alpha,{str(true_alpha)}\", file=text_file)\n",
    "    print(f\"true_beta,{str(true_beta)}\", file=text_file)\n",
    "    print(f\"true_delta,{str(true_delta)}\", file=text_file)\n",
    "    print(f\"true_kappa,{str(true_kappa)}\", file=text_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MRes project",
   "language": "python",
   "name": "stdm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
